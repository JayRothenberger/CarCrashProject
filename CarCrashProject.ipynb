{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CarCrashProject.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DzQl5PeAi2PU"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayRothenberger/CarCrashProject/blob/master/CarCrashProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es6XW9kqiGc0"
      },
      "source": [
        "# **Car Crashes in Virginia**\n",
        "**CS 4774: Machine Learning for VA (ML4VA)**\n",
        "\n",
        "Jay Rothenberger (jr2fh); Sindhu Ranga (sgr7vc); Sarah Zhou (syz3bv)\n",
        "****\n",
        "**Premise**:\n",
        "\n",
        "**Goal**:\n",
        "\n",
        "\n",
        "NOTE: Data set is 800k+ rows! Use a small sample size to test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzQl5PeAi2PU"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXxSnGk3izqA"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "# any number will do, as long as it is used consistently\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Ignore useless warnings (see SciPy issue #5998)\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgBbxy6tjJub"
      },
      "source": [
        "# 2. Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRBAlOejhJTF"
      },
      "source": [
        "# load dataset\n",
        "import os # in order to run file I/O operation \n",
        "from six.moves import urllib # support URL download\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://media.githubusercontent.com/media/sranga12/mlprojectcars/master/\"\n",
        "DATA_PATH = os.path.join(\"datasets\", \"crashes\")\n",
        "DATA_URL = DOWNLOAD_ROOT + \"Virginia_Crashes_102919_final.csv\"\n",
        "\n",
        "def fetch_data(data_url=DATA_URL, data_path=DATA_PATH):\n",
        "    \"\"\"Fetch data from a remote URL to Colab file system\"\"\"\n",
        "    if not os.path.isdir(data_path):\n",
        "        os.makedirs(data_path)\n",
        "    csv_path = os.path.join(data_path, \"Virginia_Crashes_102919_final.csv\")\n",
        "    urllib.request.urlretrieve(data_url, csv_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iNS0SKajnnf"
      },
      "source": [
        "fetch_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg8PxdNcjpb1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_data(data_path = DATA_PATH):\n",
        "    \"\"\"Load Data into Workspace from a CSV\"\"\"\n",
        "    csv_path = os.path.join(data_path,\"Virginia_Crashes_102919_final.csv\")\n",
        "    columns = [\"X\", \"Y\", \"VDOT_District\", \"Rte_Nm\",\n",
        "                                                \"Crash_Year\", \"Crash_Mo\", \"Crash_Day\", \n",
        "                                                \"Crash_Military_Tm\", \"Collision_Type\", \n",
        "                                                \"Crash_Severity\", \"Persons_Killed\", \n",
        "                                                \"Light_Condition\", \"Weather_Condition\", \n",
        "                                                \"Roadway_Surface_Cond\", \"VSP_Used\", \"Rns_Mp\", \n",
        "                                                \"Driverage_average\", \"Drivergen_average\"]\n",
        "    df = pd.read_csv(csv_path)\n",
        "    return df.drop(df.index[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkHAYQMLjrJ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "4d7b9477-d0df-4810-f55b-2a3a9e54484c"
      },
      "source": [
        "crashes = load_data()\n",
        "crashes_list = []\n",
        "\n",
        "print(crashes.head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "            X          Y  ... Unnamed: 18 Unnamed: 19\n",
            "1  -80.898183  36.947187  ...         NaN         NaN\n",
            "2  -80.578353  37.090327  ...         NaN         NaN\n",
            "3  -78.926593  38.358578  ...         NaN         NaN\n",
            "4  -77.610592  39.140818  ...         NaN         NaN\n",
            "5  -77.466652  38.367778  ...         NaN         NaN\n",
            "6  -76.684652  37.305017  ...         NaN         NaN\n",
            "7  -79.827623  37.277897  ...         NaN         NaN\n",
            "8  -77.104892  37.785908  ...         NaN         NaN\n",
            "9  -77.606532  39.139458  ...         NaN         NaN\n",
            "10 -77.564362  38.712618  ...         NaN         NaN\n",
            "\n",
            "[10 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMGKVt6tpJQp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "ef66a486-8be5-4738-e3a0-3e4a6d31d968"
      },
      "source": [
        "# Provide a quick summary of the data including name of features, count, and type\n",
        "crashes.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 817474 entries, 1 to 817474\n",
            "Data columns (total 20 columns):\n",
            "X                       815986 non-null float64\n",
            "Y                       815986 non-null float64\n",
            "VDOT_District           817474 non-null object\n",
            "Rte_Nm                  817242 non-null object\n",
            "Crash_Dt                817474 non-null object\n",
            "Crash_Military_Tm       817474 non-null int64\n",
            "Collision_Type          817474 non-null object\n",
            "Crash_Severity          817474 non-null object\n",
            "Persons_Killed          817474 non-null int64\n",
            "Light_Condition         817474 non-null object\n",
            "Weather_Condition       817474 non-null object\n",
            "Roadway_Surface_Cond    817474 non-null object\n",
            "VSP_Used                817474 non-null int64\n",
            "Rns_Mp                  771815 non-null float64\n",
            "Driverage_average       817474 non-null object\n",
            "Drivergen_average       817474 non-null float64\n",
            "Unnamed: 16             0 non-null float64\n",
            "Unnamed: 17             0 non-null float64\n",
            "Unnamed: 18             0 non-null float64\n",
            "Unnamed: 19             1 non-null object\n",
            "dtypes: float64(7), int64(3), object(10)\n",
            "memory usage: 131.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkc1_XuOpZjO"
      },
      "source": [
        "# 3. Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Zbn30e9jjW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "3354949a-11b4-4ec6-9fd0-935799af9078"
      },
      "source": [
        "crashes.iloc[23572]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "X                                                     -77.3281\n",
              "Y                                                      38.6398\n",
              "VDOT_District                              9.Northern Virginia\n",
              "Rte_Nm                                        R-VA076SC00784EB\n",
              "Crash_Dt                              2013-01-10T00:00:00.000Z\n",
              "Crash_Military_Tm                                         1625\n",
              "Collision_Type                      9. Fixed Object - Off Road\n",
              "Crash_Severity                                 A.Severe Injury\n",
              "Persons_Killed                                               0\n",
              "Light_Condition                                        3. Dusk\n",
              "Weather_Condition       1. No Adverse Condition (Clear/Cloudy)\n",
              "Roadway_Surface_Cond                                    1. Dry\n",
              "VSP_Used                                                     7\n",
              "Rns_Mp                                                 4.86926\n",
              "Driverage_average                                           25\n",
              "Drivergen_average                                            0\n",
              "Unnamed: 16                                                NaN\n",
              "Unnamed: 17                                                NaN\n",
              "Unnamed: 18                                                NaN\n",
              "Unnamed: 19                                                NaN\n",
              "Name: 23573, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk9zvQ0o_DHk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "2727881b-007c-4d87-e0f9-fe49d9a0676f"
      },
      "source": [
        "del crashes['Rte_Nm']\n",
        "del crashes['Unnamed: 16']\n",
        "del crashes['Unnamed: 17']\n",
        "del crashes['Unnamed: 18']\n",
        "del crashes['Unnamed: 19']\n",
        "del crashes['Crash_Dt']\n",
        "divzeros = crashes.loc[crashes['Driverage_average'] == '#DIV/0!']\n",
        "crashes = crashes.drop(divzeros.index)\n",
        "incomplete_rows =  crashes[crashes.isnull().any(axis=1)]\n",
        "crashes = crashes.drop(incomplete_rows.index)\n",
        "\n",
        "for col in crashes:\n",
        "  NA = crashes.loc[crashes[col] == 'Not Applicable']\n",
        "  crashes = crashes.drop(NA.index)\n",
        "\n",
        "notprovided = crashes.loc[crashes['Collision_Type'] == 'Not Provided']\n",
        "crashes = crashes.drop(notprovided.index)\n",
        "crashes = crashes.dropna()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeDfz4bWKuUU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "046da70f-3165-48cd-d144-ea4119f3419e"
      },
      "source": [
        "crashes.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 759465 entries, 1 to 817474\n",
            "Data columns (total 14 columns):\n",
            "X                       759465 non-null float64\n",
            "Y                       759465 non-null float64\n",
            "VDOT_District           759465 non-null object\n",
            "Crash_Military_Tm       759465 non-null int64\n",
            "Collision_Type          759465 non-null object\n",
            "Crash_Severity          759465 non-null object\n",
            "Persons_Killed          759465 non-null int64\n",
            "Light_Condition         759465 non-null object\n",
            "Weather_Condition       759465 non-null object\n",
            "Roadway_Surface_Cond    759465 non-null object\n",
            "VSP_Used                759465 non-null int64\n",
            "Rns_Mp                  759465 non-null float64\n",
            "Driverage_average       759465 non-null object\n",
            "Drivergen_average       759465 non-null float64\n",
            "dtypes: float64(4), int64(3), object(7)\n",
            "memory usage: 86.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_En1Jb4jI-Cn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2f6bfe57-cd4d-42a3-bf42-9c9fb20d4f9f"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# split dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set = train_test_split(crashes, test_size=0.05, train_size = 0.3)\n",
        "\n",
        "X_train = train_set.drop(\"Crash_Severity\", axis=1); # drop labels for training set\n",
        "y_train = train_set[\"Crash_Severity\"].copy();\n",
        "X_test = test_set.drop(\"Crash_Severity\", axis=1);\n",
        "y_test = test_set[\"Crash_Severity\"].copy();\n",
        "\n",
        "y_train = np.array([y_train]).T\n",
        "y_test = np.array([y_test]).T\n",
        "\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('std_scaler', StandardScaler()), \n",
        "]) \n",
        "\n",
        "num_attribs = list(crashes.drop([\"VDOT_District\", \"Collision_Type\", \n",
        "                                 \"Light_Condition\", \"Weather_Condition\", \n",
        "                                 \"Roadway_Surface_Cond\", \"Crash_Severity\"], axis=1))\n",
        "cat_attribs = [\"VDOT_District\", \"Collision_Type\", \"Light_Condition\", \n",
        "               \"Weather_Condition\", \"Roadway_Surface_Cond\"]\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"ohe\", OneHotEncoder(), cat_attribs), \n",
        "    ])\n",
        "\n",
        "X_train = full_pipeline.fit_transform(X_train)\n",
        "X_test = full_pipeline.transform(X_test)\n",
        "\n",
        "X_valid = X_train[:45000]\n",
        "X_train = X_train[45000:]\n",
        "\n",
        "y_valid = y_train[:45000]\n",
        "y_train = y_train[45000:]\n",
        "\n",
        "# are dimensions correct?\n",
        "print(np.shape(X_test)) # x\n",
        "print(np.shape(y_train)) # x1\n",
        "print(np.shape(y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37974, 61)\n",
            "(182838, 1)\n",
            "(45000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joqLNecajTjd"
      },
      "source": [
        "# 5. Testing Different Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j35EU5l2RYTs"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0SVNOZ6hwvL"
      },
      "source": [
        "# test different models for data (and explain reasoning in text)\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import accuracy_score as accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Dk0Op4McJH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "22f6a988-5701-4a17-cab4-1ef450d07f37"
      },
      "source": [
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37974, 61) (37974, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtm4S9s72Bpt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b073da64-9a10-4688-f4e4-7e62c534f8de"
      },
      "source": [
        "# Linear OvR\n",
        "linear_ovr_svm = SVC(kernel=\"linear\", C=1, gamma=\"scale\", decision_function_shape=\"ovr\")\n",
        "linear_ovr_svm.fit(X_train, y_train)\n",
        "y_pred=linear_ovr_svm.predict(X_test)\n",
        "cv = accuracy(y_pred, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fIMOYsEHu2K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f955db6f-248a-470d-ba84-a8c78856f112"
      },
      "source": [
        "print(cv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6604344963791968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w4JLFvWHJRs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "fb2a7201-53ba-428c-c8b3-eb04bd429d49"
      },
      "source": [
        "# Linear OvO\n",
        "linear_ovo_svm = SVC(kernel=\"linear\", C=1, gamma=\"scale\", decision_function_shape=\"ovo\")\n",
        "linear_ovo_svm.fit(X_train, y_train)\n",
        "y_pred=linear_ovo_svm.predict(X_test)\n",
        "print(accuracy(y_pred, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6608294930875576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk1m9FmXXpPS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "b64fd945-dc2c-4c41-f8e9-1f8bd0356b4a"
      },
      "source": [
        "# RBF Kernel\n",
        "linear_ovo_svm = SVC(kernel=\"rbf\", C=1, gamma=\"scale\", decision_function_shape=\"ovo\")\n",
        "linear_ovo_svm.fit(X_train, y_train)\n",
        "y_pred=linear_ovo_svm.predict(X_test)\n",
        "print(accuracy(y_pred, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6603028308097433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YexHO7R5HsVc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "13e7667c-e4ba-4d15-c3dd-a6a7e880c72c"
      },
      "source": [
        "# RBF Kernel\n",
        "rbf_ovr_svm = SVC(kernel=\"rbf\", C=1, gamma=\"scale\", decision_function_shape=\"ovr\")\n",
        "rbf_ovr_svm.fit(X_train, y_train)\n",
        "y_pred=rbf_ovr_svm.predict(X_test)\n",
        "print(accuracy(y_pred, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6603028308097433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_AWOSZP0_If"
      },
      "source": [
        "## Neural Network sans Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adk-gAl40_r9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2907362d-5432-4e97-92b7-f091609abec6"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "# INSERT THE LINE BELOW TO SELECT TENSORFLOW 2.0\n",
        "%tensorflow_version 2.x\n",
        "# TensorFlow ≥2.0-preview is required\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "#assert tf.__version__ >= \"2.0\"\n",
        "from tensorflow import keras\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
        "model = keras.models.Sequential([\n",
        "keras.layers.Dense(X_train.shape[1],input_dim=X_train.shape[1], activation='relu'),\n",
        "keras.layers.Dense(200, activation=\"relu\"),\n",
        "keras.layers.Dense(150, activation=\"relu\"),\n",
        "keras.layers.Dense(120, activation=\"relu\"),\n",
        "keras.layers.Dense(81, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "#.6615"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5q11251Bre4"
      },
      "source": [
        "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(),\n",
        "              metrics=[keras.metrics.sparse_categorical_accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3XeGxmgRJOY"
      },
      "source": [
        "# Encoding the data to be entirely numerical for the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e39WBD2Gq9kE"
      },
      "source": [
        "def encode_y(arr):\n",
        "  for i in range(len(arr)):\n",
        "    arr[i][0] = ord(arr[i][0][0])\n",
        "  #z = max(arr) + 1\n",
        "  z=1\n",
        "  for i in range(len(arr)):\n",
        "    arr[i] /= z\n",
        "  return arr\n",
        "\n",
        "y_train = encode_y(y_train)\n",
        "y_valid = encode_y(y_valid)\n",
        "y_test = encode_y(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B10-B0nkBvei",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "0eba98e5-65d3-4d23-9743-12a792e2cd7d"
      },
      "source": [
        "X_train.todense()\n",
        "X_valid.todense()\n",
        "X_test.todense()\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "Train on 182838 samples, validate on 45000 samples\n",
            "Epoch 1/10\n",
            "182838/182838 [==============================] - 15s 82us/sample - loss: 1.0077 - sparse_categorical_accuracy: 0.6542 - val_loss: 0.9311 - val_sparse_categorical_accuracy: 0.6591\n",
            "Epoch 2/10\n",
            "182838/182838 [==============================] - 15s 81us/sample - loss: 0.9303 - sparse_categorical_accuracy: 0.6577 - val_loss: 0.9187 - val_sparse_categorical_accuracy: 0.6625\n",
            "Epoch 3/10\n",
            "182838/182838 [==============================] - 16s 85us/sample - loss: 0.9210 - sparse_categorical_accuracy: 0.6607 - val_loss: 0.9314 - val_sparse_categorical_accuracy: 0.6619\n",
            "Epoch 4/10\n",
            "182838/182838 [==============================] - 16s 88us/sample - loss: 0.9169 - sparse_categorical_accuracy: 0.6613 - val_loss: 0.9145 - val_sparse_categorical_accuracy: 0.6630\n",
            "Epoch 5/10\n",
            "182838/182838 [==============================] - 18s 98us/sample - loss: 0.9145 - sparse_categorical_accuracy: 0.6613 - val_loss: 0.9150 - val_sparse_categorical_accuracy: 0.6631\n",
            "Epoch 6/10\n",
            "182838/182838 [==============================] - 17s 92us/sample - loss: 0.9122 - sparse_categorical_accuracy: 0.6613 - val_loss: 0.9091 - val_sparse_categorical_accuracy: 0.6628\n",
            "Epoch 7/10\n",
            "182838/182838 [==============================] - 19s 103us/sample - loss: 0.9106 - sparse_categorical_accuracy: 0.6615 - val_loss: 0.9063 - val_sparse_categorical_accuracy: 0.6626\n",
            "Epoch 8/10\n",
            "182838/182838 [==============================] - 17s 94us/sample - loss: 0.9092 - sparse_categorical_accuracy: 0.6615 - val_loss: 0.9054 - val_sparse_categorical_accuracy: 0.6637\n",
            "Epoch 9/10\n",
            "182838/182838 [==============================] - 18s 97us/sample - loss: 0.9077 - sparse_categorical_accuracy: 0.6613 - val_loss: 0.9070 - val_sparse_categorical_accuracy: 0.6634\n",
            "Epoch 10/10\n",
            "182838/182838 [==============================] - 18s 99us/sample - loss: 0.9065 - sparse_categorical_accuracy: 0.6612 - val_loss: 0.9063 - val_sparse_categorical_accuracy: 0.6637\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "37974/37974 [==============================] - 2s 41us/sample - loss: 0.9157 - sparse_categorical_accuracy: 0.6602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9156903901823187, 0.6602149]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VYcwXE-QweV"
      },
      "source": [
        "## A Basic Shallow Sequential Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHW7oEKah1C9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "45fc2425-5154-4130-eb5e-01b986b49b9f"
      },
      "source": [
        "X_train.todense()\n",
        "X_valid.todense()\n",
        "X_test.todense()\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "keras.layers.Dense(200,input_dim=X_train.shape[1], activation='relu'),\n",
        "keras.layers.Dense(200, activation=\"relu\"),\n",
        "keras.layers.Dense(150, activation=\"relu\"),\n",
        "keras.layers.Dense(120, activation=\"relu\"),\n",
        "keras.layers.Dense(120, activation=\"relu\"),\n",
        "keras.layers.Dense(81, activation=\"softmax\"),\n",
        "])\n",
        "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(),\n",
        "              metrics=[keras.metrics.sparse_categorical_accuracy])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "\n",
        "model.evaluate(X_test, y_test)\n",
        "#0.6659"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "Train on 182839 samples, validate on 45000 samples\n",
            "Epoch 1/10\n",
            "182839/182839 [==============================] - 19s 103us/sample - loss: 0.9990 - sparse_categorical_accuracy: 0.6550 - val_loss: 0.9384 - val_sparse_categorical_accuracy: 0.6586\n",
            "Epoch 2/10\n",
            "182839/182839 [==============================] - 19s 102us/sample - loss: 0.9310 - sparse_categorical_accuracy: 0.6580 - val_loss: 0.9276 - val_sparse_categorical_accuracy: 0.6615\n",
            "Epoch 3/10\n",
            "182839/182839 [==============================] - 18s 99us/sample - loss: 0.9221 - sparse_categorical_accuracy: 0.6606 - val_loss: 0.9191 - val_sparse_categorical_accuracy: 0.6621\n",
            "Epoch 4/10\n",
            "182839/182839 [==============================] - 18s 99us/sample - loss: 0.9173 - sparse_categorical_accuracy: 0.6611 - val_loss: 0.9142 - val_sparse_categorical_accuracy: 0.6624\n",
            "Epoch 5/10\n",
            "182839/182839 [==============================] - 18s 98us/sample - loss: 0.9149 - sparse_categorical_accuracy: 0.6614 - val_loss: 0.9259 - val_sparse_categorical_accuracy: 0.6632\n",
            "Epoch 6/10\n",
            "182839/182839 [==============================] - 20s 111us/sample - loss: 0.9123 - sparse_categorical_accuracy: 0.6612 - val_loss: 0.9207 - val_sparse_categorical_accuracy: 0.6620\n",
            "Epoch 7/10\n",
            "182839/182839 [==============================] - 22s 118us/sample - loss: 0.9103 - sparse_categorical_accuracy: 0.6612 - val_loss: 0.9083 - val_sparse_categorical_accuracy: 0.6615\n",
            "Epoch 8/10\n",
            "182839/182839 [==============================] - 23s 125us/sample - loss: 0.9086 - sparse_categorical_accuracy: 0.6614 - val_loss: 0.9111 - val_sparse_categorical_accuracy: 0.6614\n",
            "Epoch 9/10\n",
            "182839/182839 [==============================] - 22s 123us/sample - loss: 0.9068 - sparse_categorical_accuracy: 0.6616 - val_loss: 0.9145 - val_sparse_categorical_accuracy: 0.6632\n",
            "Epoch 10/10\n",
            "182839/182839 [==============================] - 22s 119us/sample - loss: 0.9051 - sparse_categorical_accuracy: 0.6614 - val_loss: 0.9074 - val_sparse_categorical_accuracy: 0.6633\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "37974/37974 [==============================] - 2s 43us/sample - loss: 0.9147 - sparse_categorical_accuracy: 0.6606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9147406370774035, 0.6606099]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lKJPrkbQUlQ"
      },
      "source": [
        "## Building the Ensemble of Shallow Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDWYYILG9c2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "322ae5db-2ecb-41d0-d95a-c5b262ed8f13"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from numpy import argmax\n",
        "#ensemble of the models:\n",
        "def new_trained_model():\n",
        "  train_set, test_set = train_test_split(crashes, test_size=0.15, train_size = 0.3)\n",
        "\n",
        "  X_train = train_set.drop(\"Crash_Severity\", axis=1); # drop labels for training set\n",
        "  y_train = train_set[\"Crash_Severity\"].copy();\n",
        "\n",
        "  y_train = np.array([y_train]).T\n",
        "\n",
        "  num_pipeline = Pipeline([\n",
        "      ('std_scaler', StandardScaler()), \n",
        "  ]) \n",
        "\n",
        "  num_attribs = list(crashes.drop([\"VDOT_District\", \"Collision_Type\", \n",
        "                                  \"Light_Condition\", \"Weather_Condition\", \n",
        "                                  \"Roadway_Surface_Cond\", \"Crash_Severity\"], axis=1))\n",
        "  cat_attribs = [\"VDOT_District\", \"Collision_Type\", \"Light_Condition\", \n",
        "                \"Weather_Condition\", \"Roadway_Surface_Cond\"]\n",
        "\n",
        "  full_pipeline = ColumnTransformer([\n",
        "          (\"num\", num_pipeline, num_attribs),\n",
        "          (\"ohe\", OneHotEncoder(), cat_attribs), \n",
        "      ])\n",
        "\n",
        "  X_train = full_pipeline.fit_transform(X_train)\n",
        "\n",
        "  X_valid = X_train[:45000]\n",
        "  X_train = X_train[45000:]\n",
        "\n",
        "  y_valid = y_train[:45000]\n",
        "  y_train = y_train[45000:]\n",
        "  #now we have new data, we need to encode it\n",
        "  y_train = encode_y(y_train)\n",
        "  y_valid = encode_y(y_valid)\n",
        "  #here we have encoded it, now we need to create a new model\n",
        "\n",
        "  X_train.todense()\n",
        "  X_valid.todense()\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "  keras.layers.Dense(200,input_dim=61, activation='relu'),\n",
        "  keras.layers.Dense(200, activation=\"relu\"),\n",
        "  keras.layers.Dense(150, activation=\"relu\"),\n",
        "  keras.layers.Dense(120, activation=\"relu\"),\n",
        "  keras.layers.Dense(81, activation=\"softmax\"),\n",
        "  ])\n",
        "  model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
        "                optimizer=keras.optimizers.SGD(),\n",
        "                metrics=[keras.metrics.sparse_categorical_accuracy])\n",
        "\n",
        "  trained = model.fit(X_train, y_train, epochs=3,\n",
        "                      validation_data=(X_valid, y_valid))\n",
        "  return model\n",
        "\n",
        "senators = []\n",
        "for i in range(7):\n",
        "  senators.append(new_trained_model())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "Train on 182838 samples, validate on 45000 samples\n",
            "Epoch 1/3\n",
            "182838/182838 [==============================] - 18s 98us/sample - loss: 0.9888 - sparse_categorical_accuracy: 0.6543 - val_loss: 0.9327 - val_sparse_categorical_accuracy: 0.6597\n",
            "Epoch 2/3\n",
            "182838/182838 [==============================] - 18s 97us/sample - loss: 0.9257 - sparse_categorical_accuracy: 0.6594 - val_loss: 0.9297 - val_sparse_categorical_accuracy: 0.6602\n",
            "Epoch 3/3\n",
            "182838/182838 [==============================] - 19s 107us/sample - loss: 0.9197 - sparse_categorical_accuracy: 0.6605 - val_loss: 0.9251 - val_sparse_categorical_accuracy: 0.6621\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "Train on 182838 samples, validate on 45000 samples\n",
            "Epoch 1/3\n",
            "182838/182838 [==============================] - 21s 112us/sample - loss: 0.9850 - sparse_categorical_accuracy: 0.6555 - val_loss: 0.9441 - val_sparse_categorical_accuracy: 0.6535\n",
            "Epoch 2/3\n",
            "182838/182838 [==============================] - 21s 112us/sample - loss: 0.9249 - sparse_categorical_accuracy: 0.6596 - val_loss: 0.9313 - val_sparse_categorical_accuracy: 0.6575\n",
            "Epoch 3/3\n",
            "182838/182838 [==============================] - 20s 112us/sample - loss: 0.9182 - sparse_categorical_accuracy: 0.6609 - val_loss: 0.9279 - val_sparse_categorical_accuracy: 0.6572\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "Train on 182838 samples, validate on 45000 samples\n",
            "Epoch 1/3\n",
            "182838/182838 [==============================] - 20s 112us/sample - loss: 0.9987 - sparse_categorical_accuracy: 0.6528 - val_loss: 0.9390 - val_sparse_categorical_accuracy: 0.6582\n",
            "Epoch 2/3\n",
            "182838/182838 [==============================] - 21s 117us/sample - loss: 0.9288 - sparse_categorical_accuracy: 0.6570 - val_loss: 0.9190 - val_sparse_categorical_accuracy: 0.6621\n",
            "Epoch 3/3\n",
            "182838/182838 [==============================] - 20s 109us/sample - loss: 0.9215 - sparse_categorical_accuracy: 0.6590 - val_loss: 0.9138 - val_sparse_categorical_accuracy: 0.6627\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "Train on 182838 samples, validate on 45000 samples\n",
            "Epoch 1/3\n",
            "182838/182838 [==============================] - 21s 113us/sample - loss: 0.9907 - sparse_categorical_accuracy: 0.6556 - val_loss: 0.9266 - val_sparse_categorical_accuracy: 0.6573\n",
            "Epoch 2/3\n",
            "182838/182838 [==============================] - 21s 113us/sample - loss: 0.9273 - sparse_categorical_accuracy: 0.6586 - val_loss: 0.9179 - val_sparse_categorical_accuracy: 0.6616\n",
            "Epoch 3/3\n",
            "182838/182838 [==============================] - 21s 115us/sample - loss: 0.9202 - sparse_categorical_accuracy: 0.6604 - val_loss: 0.9188 - val_sparse_categorical_accuracy: 0.6624\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "Train on 182838 samples, validate on 45000 samples\n",
            "Epoch 1/3\n",
            "182838/182838 [==============================] - 19s 106us/sample - loss: 1.0043 - sparse_categorical_accuracy: 0.6534 - val_loss: 0.9290 - val_sparse_categorical_accuracy: 0.6577\n",
            "Epoch 2/3\n",
            "182838/182838 [==============================] - 21s 115us/sample - loss: 0.9293 - sparse_categorical_accuracy: 0.6587 - val_loss: 0.9198 - val_sparse_categorical_accuracy: 0.6616\n",
            "Epoch 3/3\n",
            "182838/182838 [==============================] - 20s 108us/sample - loss: 0.9219 - sparse_categorical_accuracy: 0.6606 - val_loss: 0.9135 - val_sparse_categorical_accuracy: 0.6620\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "Train on 182838 samples, validate on 45000 samples\n",
            "Epoch 1/3\n",
            "182838/182838 [==============================] - 20s 112us/sample - loss: 1.0026 - sparse_categorical_accuracy: 0.6534 - val_loss: 0.9398 - val_sparse_categorical_accuracy: 0.6554\n",
            "Epoch 2/3\n",
            "182838/182838 [==============================] - 21s 117us/sample - loss: 0.9306 - sparse_categorical_accuracy: 0.6571 - val_loss: 0.9235 - val_sparse_categorical_accuracy: 0.6602\n",
            "Epoch 3/3\n",
            "182838/182838 [==============================] - 21s 113us/sample - loss: 0.9228 - sparse_categorical_accuracy: 0.6598 - val_loss: 0.9188 - val_sparse_categorical_accuracy: 0.6608\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "Train on 182838 samples, validate on 45000 samples\n",
            "Epoch 1/3\n",
            "182838/182838 [==============================] - 21s 115us/sample - loss: 0.9925 - sparse_categorical_accuracy: 0.6539 - val_loss: 0.9336 - val_sparse_categorical_accuracy: 0.6543\n",
            "Epoch 2/3\n",
            "182838/182838 [==============================] - 21s 112us/sample - loss: 0.9282 - sparse_categorical_accuracy: 0.6585 - val_loss: 0.9330 - val_sparse_categorical_accuracy: 0.6572\n",
            "Epoch 3/3\n",
            "182838/182838 [==============================] - 21s 114us/sample - loss: 0.9201 - sparse_categorical_accuracy: 0.6602 - val_loss: 0.9220 - val_sparse_categorical_accuracy: 0.6594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGE9LLyyQcHP"
      },
      "source": [
        "## Implementing the Basic Voting Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OboM1j9FcLzg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "dfeb8017-99f5-44b5-dad0-cff08451380d"
      },
      "source": [
        "from numpy import array\n",
        "import statistics\n",
        "def vote(models, X_test):\n",
        "\ty = []\n",
        "\n",
        "\ty_pred = [model.predict_classes(X_test) for model in models]\n",
        "\ty_pred = array(y_pred).T\n",
        "\n",
        "\tprint(y_pred)\n",
        "\n",
        "\tfor i in range(len(y_pred)):\n",
        "\t\ttry:\n",
        "\t\t\ty.append([statistics.mode(y_pred[i])])\n",
        "\t\texcept:\n",
        "\t\t\ty.append([statistics.median(y_pred[i])])\n",
        "\t\n",
        "\tprint(array(y))\n",
        "\n",
        "\treturn array(y)\n",
        "\n",
        "def evaluate_senators(members, X_test, y_test):\n",
        "\tsame = 0\n",
        "\ty_pred = vote(members, X_test)\n",
        "\tfor i in range(len(y_pred)):\n",
        "\t\tif y_pred[i] == y_test[i]:\n",
        "\t\t\tsame+=1\n",
        "\treturn same/len(y_test)\n",
        "\n",
        "print(evaluate_senators(senators, X_test, y_test))\n",
        "#.65676"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "[[80 80 80 ... 80 80 80]\n",
            " [80 80 80 ... 80 80 80]\n",
            " [80 80 66 ... 80 80 80]\n",
            " ...\n",
            " [80 80 80 ... 80 80 80]\n",
            " [80 80 80 ... 80 80 80]\n",
            " [80 80 80 ... 80 80 80]]\n",
            "[[80]\n",
            " [80]\n",
            " [80]\n",
            " ...\n",
            " [80]\n",
            " [80]\n",
            " [80]]\n",
            "0.6608833430624257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCnN5vZ6exBw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "59680ca2-e1da-4684-99b4-a2392a795fdc"
      },
      "source": [
        "train_set, test_set = train_test_split(crashes, test_size=0.3, train_size = 0.7)\n",
        "\n",
        "X_train = train_set.drop(\"Crash_Severity\", axis=1); # drop labels for training set\n",
        "y_train = train_set[\"Crash_Severity\"].copy();\n",
        "X_test = test_set.drop(\"Crash_Severity\", axis=1);\n",
        "y_test = test_set[\"Crash_Severity\"].copy();\n",
        "\n",
        "y_train = np.array([y_train]).T\n",
        "y_test = np.array([y_test]).T\n",
        "\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('std_scaler', StandardScaler()), \n",
        "]) \n",
        "\n",
        "num_attribs = list(crashes.drop([\"VDOT_District\", \"Collision_Type\", \n",
        "                                 \"Light_Condition\", \"Weather_Condition\", \n",
        "                                 \"Roadway_Surface_Cond\", \"Crash_Severity\"], axis=1))\n",
        "cat_attribs = [\"VDOT_District\", \"Collision_Type\", \"Light_Condition\", \n",
        "               \"Weather_Condition\", \"Roadway_Surface_Cond\"]\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"ohe\", OneHotEncoder(), cat_attribs), \n",
        "    ])\n",
        "\n",
        "X_train = full_pipeline.fit_transform(X_train)\n",
        "X_test = full_pipeline.transform(X_test)\n",
        "\n",
        "X_valid = X_train[:45000]\n",
        "X_train = X_train[45000:]\n",
        "\n",
        "y_valid = y_train[:45000]\n",
        "y_train = y_train[45000:]\n",
        "\n",
        "y_train = encode_y(y_train)\n",
        "y_valid = encode_y(y_valid)\n",
        "y_test = encode_y(y_test)\n",
        "#here we have encoded it, now we need to create a new model\n",
        "\n",
        "X_train.todense()\n",
        "X_valid.todense()\n",
        "X_test.todense()\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "keras.layers.Dense(200,input_dim=61, activation='elu'),\n",
        "keras.layers.Dense(200, activation=\"elu\"),\n",
        "keras.layers.Dense(200, activation=\"elu\"),\n",
        "keras.layers.Dense(200, activation=\"elu\"),\n",
        "keras.layers.Dense(200, activation=\"elu\"),\n",
        "keras.layers.Dense(200, activation=\"elu\"),\n",
        "keras.layers.Dense(200, activation=\"elu\"),\n",
        "keras.layers.Dense(200, activation=\"elu\"),\n",
        "keras.layers.Dense(200, activation=\"elu\"),\n",
        "keras.layers.Dense(200, activation=\"elu\"),\n",
        "keras.layers.Dense(200, activation=\"elu\"),\n",
        "keras.layers.Dense(200, activation=\"elu\"),\n",
        "keras.layers.Dense(200, activation=\"elu\"),\n",
        "keras.layers.Dense(150, activation=\"elu\"),\n",
        "keras.layers.Dense(120, activation=\"elu\"),\n",
        "keras.layers.Dense(100, activation=\"softmax\"),\n",
        "])\n",
        "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(),\n",
        "              metrics=[keras.metrics.sparse_categorical_accuracy])\n",
        "\n",
        "trained = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "#6606"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "Train on 486624 samples, validate on 45000 samples\n",
            "Epoch 1/10\n",
            "486624/486624 [==============================] - 124s 255us/sample - loss: 0.9371 - sparse_categorical_accuracy: 0.6592 - val_loss: 0.9128 - val_sparse_categorical_accuracy: 0.6628\n",
            "Epoch 2/10\n",
            "486624/486624 [==============================] - 123s 253us/sample - loss: 0.9171 - sparse_categorical_accuracy: 0.6607 - val_loss: 0.9125 - val_sparse_categorical_accuracy: 0.6620\n",
            "Epoch 3/10\n",
            "486624/486624 [==============================] - 122s 250us/sample - loss: 0.9126 - sparse_categorical_accuracy: 0.6609 - val_loss: 0.9059 - val_sparse_categorical_accuracy: 0.6627\n",
            "Epoch 4/10\n",
            "486624/486624 [==============================] - 136s 279us/sample - loss: 0.9074 - sparse_categorical_accuracy: 0.6609 - val_loss: 0.8999 - val_sparse_categorical_accuracy: 0.6628\n",
            "Epoch 5/10\n",
            "486624/486624 [==============================] - 129s 265us/sample - loss: 0.9041 - sparse_categorical_accuracy: 0.6610 - val_loss: 0.8981 - val_sparse_categorical_accuracy: 0.6629\n",
            "Epoch 6/10\n",
            "486624/486624 [==============================] - 121s 248us/sample - loss: 0.9016 - sparse_categorical_accuracy: 0.6611 - val_loss: 0.8968 - val_sparse_categorical_accuracy: 0.6632\n",
            "Epoch 7/10\n",
            "486624/486624 [==============================] - 113s 231us/sample - loss: 0.8992 - sparse_categorical_accuracy: 0.6612 - val_loss: 0.8926 - val_sparse_categorical_accuracy: 0.6627\n",
            "Epoch 8/10\n",
            "486624/486624 [==============================] - 112s 230us/sample - loss: 0.8972 - sparse_categorical_accuracy: 0.6613 - val_loss: 0.8926 - val_sparse_categorical_accuracy: 0.6632\n",
            "Epoch 9/10\n",
            "486624/486624 [==============================] - 128s 264us/sample - loss: 0.8956 - sparse_categorical_accuracy: 0.6614 - val_loss: 0.8889 - val_sparse_categorical_accuracy: 0.6630\n",
            "Epoch 10/10\n",
            "486624/486624 [==============================] - 119s 244us/sample - loss: 0.8941 - sparse_categorical_accuracy: 0.6613 - val_loss: 0.8963 - val_sparse_categorical_accuracy: 0.6632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpSpyNo6Qnrk"
      },
      "source": [
        "## A Deep 103 Layer Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4giwPv2kFats"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(200,input_dim=61, activation='elu'))\n",
        "model.add(keras.layers.Dense(200, activation=\"selu\",\n",
        "                             kernel_initializer=\"lecun_normal\"))\n",
        "for layer in range(100):\n",
        "    model.add(keras.layers.Dense(200, activation=\"selu\",\n",
        "                                 kernel_initializer=\"lecun_normal\"))\n",
        "model.add(keras.layers.Dense(81, activation=\"softmax\"))\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWjukdhlK4cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "cc3c2b95-8518-4d31-ec68-d170dc31acc7"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=3,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "Train on 486624 samples, validate on 45000 samples\n",
            "Epoch 1/3\n",
            "486624/486624 [==============================] - 731s 2ms/sample - loss: 0.9449 - accuracy: 0.6575 - val_loss: 0.9244 - val_accuracy: 0.6610\n",
            "Epoch 2/3\n",
            "486624/486624 [==============================] - 677s 1ms/sample - loss: 0.9189 - accuracy: 0.6609 - val_loss: 0.9080 - val_accuracy: 0.6629\n",
            "Epoch 3/3\n",
            "486624/486624 [==============================] - 715s 1ms/sample - loss: 0.9108 - accuracy: 0.6609 - val_loss: 0.9129 - val_accuracy: 0.6628\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}